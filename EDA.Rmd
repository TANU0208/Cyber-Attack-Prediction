---
title: "EDA: Detecting Cyber Attacks in Water Networks"
output: html_notebook
---

```{r}
# Remove all variables from the R environment to create a fresh start
rm(list=ls())

# Load datasets
train1 <- read.csv("train_dataset01.csv")
train2 <- read.csv("train_dataset02.csv")
test <- read.csv("test_dataset.csv")
```

I tried printing out the summaries but they are too long to be immediately useful. Let's try plots of variables for times with cyber attacks and times without 

## Histograms
```{r}
library(tidyverse)
library(ggplot2)

train2[train2$ATT_FLAG == "True",] %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram(binwidth = 25)
```

```{r}
train2[train2$ATT_FLAG == "False",] %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram(binwidth = 10)
```

## Baseline Model
I still cannot see much other than that distributions between observations with attacks and no attacks are different. This is a good sign for now. We can look at distribution of attacks and no-attacks and see what is our baseline F-scores in the training data set

```{r}
distribution <- table(train2$ATT_FLAG)
distribution
```
 
We can predict all True and see what is our score. 
```{r}
# Precision
precision <- distribution[2]/sum(distribution)
precision

# Recall
recall <- distribution[2]/distribution[2]
recall

# F score
(2 * precision * recall)/(precision + recall)
```
 
## See Distribution of Categorical Data
Maybe we can look at distribution of catogorical columns when grouped by their ATT_FLAG and see if we can identify significant features. 
```{r}
cats = c("STATUS_PU1", "STATUS_PU2", "STATUS_PU4", "STATUS_PU6", "STATUS_PU7", "STATUS_PU10",  "STATUS_PU11", "STATUS_V2")

# Proportion table for obs with attacks
prop.table(sapply(train2[train2$ATT_FLAG == "True", cats], table), margin = 2)

# Proportion table for obs without attacks
prop.table(sapply(train2[train2$ATT_FLAG == "False", cats], table), margin = 2)
```

From the above two tables, it seems that we can ignore PU1, PU4 and PU11 since the distributions seem to be the same regardless of whether there is an attack or not. To be sure, we need to do a t-test. (We are definitely ignoring PU3, PU5, PU8 and PU9 since they only have one level)

```{r}
for (col in cats) {
  result <- t.test(
              as.logical(train2[train2$ATT_FLAG == "True", col]),
              as.logical(train2[train2$ATT_FLAG == "False", col])
            )
  print(col)
  print(result)
}
```

The t-test shows us that among the catergorical features, we cannot reject the hypothesis that STATUS_PU4's mean differs between observations with attacks and observations without attacks. i.e. we may want to consider removing STATUS_PU4 in our models. 

We can do the same analysis for non-catergorical features. 
# TODO

## Looking for Patterns in time series
We notice that the data has a data component. Perhaps we should look at it as a time series?
```{r}
train2.ts <- ts(train2)
str(train2.ts)
plot.ts(train2.ts[,"ATT_FLAG"], ylab = "ATT_FLAG")
```

This looks interesting. From this plot we can see that attacks occur over a duration and there are 7 attacks in this set of training data. This perhaps also suggests that we cannot treat observations independently. If the previous observation is an attack, the next observation is more likely to be an attack as well since attack observations come together. 

Another thing is, if we just throw a logistic regression model at this data, we are assuming that all 7 attacks have the same patterns. Perhaps the attacks are executed differently? Maybe I can use clustering techniques to see how many different types of attacks we have here. We have at most 7 possible different kinds of attacks. If we can identify that, maybe we can build one model to identify each type of attack. Which could improve our performance.

We can look at other features and see how they vary with time. 
```{r}
# for (col in colnames(train2.ts)) {
#   plot.ts(train2.ts[,col], ylab=col)
# }
```

Ok there are way too many plots and my R studio is lagging now so I have to comment them out

From the plots we can see a few things. First, there doesn't seem to be a decreasing or increasing trend in the features across time. This is good as things are pretty constant other than the attacks. 

Second, different attacks correspond different anomalies in the features. This confirms our hypothesis that there are more than one type of attack. 

Third, there are many features that just remain constant throughout so we can ignore them. 

There is also a lot of noise in the data. We might want to find a way to clean that up. 

```{r}
ignore = c("LEVEL_T5", "FLOW_PU3", "FLOW_PU5", "FLOW_PU9", "STATUS_PU3", "STATUS_PU5", "STATUS_PU8", "STATUS_PU9")
train2.small <- train2[ , -which(names(train2) %in% ignore)]
train2.small.ts <- ts(train2.small)

# for (col in colnames(train2.small.ts)) {
#   if (col != "DATETIME" & col != "ATT_FLAG") {
#     plot.ts(train2.small.ts[,col], ylab=col, col=c("black"))
#     par(new = TRUE)
#     plot.ts(train2.small.ts[,"ATT_FLAG"], axes=FALSE, bty = "n", xlab = "", ylab = "", col="red")
#   }
# }
```

From the above plots, it seems as if attacks 1 and 2 are very similar, 3 and 4 are very similar, and 6 and 7 are very similar. Attack 5 seems to be a slight variant from attacks 6 and 7. There seems to be 3-4 different types of attacks here. 

We can use clustering techniques to verify this. 

## Clustering

```{r}
set.seed(1)
fit <- 0
for(k in 1:10){
  clusterTrain <- kmeans(train2.small[,2:28], centers=k, nstart=20)
  fit[k] <- clusterTrain$tot.withinss
}
plot(1:10, fit)
```
After performing kmeans on the non-catergorical data, it seems that there are around 4 to 5 clusters (using elbow method) 

```{r}
# Let's see the corresponding clusters with 5 clusters
# Add clusters to df
clusterTrain <- kmeans(train2.small[,2:28], centers=5, nstart=20)
train2.small$cluster <- clusterTrain$cluster
```

```{r}
# Plot as time series to see if clustering captured the attack patterns
train2.small.ts <- ts(train2.small)
plot.ts(train2.small.ts[,"ATT_FLAG"], col="red")
par(new = TRUE)
plot.ts(train2.small.ts[,"cluster"], axes=FALSE, bty = "n", xlab = "", ylab = "", col="blue")
```

So from the plot above, we can see that kmeans totally didn't work out. This is sad. How about Hierarchical clustering?

```{r}
# With the function dist, we calculate the distance 
distances <- dist(train2.small[,2:28], method="euclidean")
dim(train2.small)
length(distances)

# Execute hierarchical clustering. We use Ward's distance method to find compact clusters.
clusterTrain <- hclust(distances, method="ward.D2")
# Plots the dendrogram. We have several movies, so the lists at the bottom cannot be read
plot(clusterTrain) 
```

```{r}
# Let's then cut the dendrogram into 5 clusters
clusters <- cutree(clusterTrain, k=5)

# Plot as time series to see if clustering captured the attack patterns
train2.small$cluster <- clusters
train2.small.ts <- ts(train2.small)
plot.ts(train2.small.ts[,"ATT_FLAG"], col="red")
par(new = TRUE)
plot.ts(train2.small.ts[,"cluster"], axes=FALSE, bty = "n", xlab = "", ylab = "", col="black")
```
Still terrible. Ugh, looks like I can't use clustering to prove anything here. What if I do clustering only on obs with attacks? 

```{r}
# First label attack numbers in train data
train2.small$attack <- rep("0", times=nrow(train2.small))

attack = 0
prev = "False"
for (i in 1:nrow(train2.small)) {
  cur = train2.small$ATT_FLAG[i]
  if (cur == "True") {
    if (prev == "False") {
      attack = attack + 1
    }
    train2.small$attack[i] <- attack 
  }
  prev = cur
}

train2.small.ts <- ts(train2.small)
plot.ts(train2.small.ts[,"ATT_FLAG"], col="red")
par(new = TRUE)
plot.ts(train2.small.ts[,"attack"], axes=FALSE, bty = "n", xlab = "", ylab = "", col="black")
```
Woohoo! Looks like I did it correctly. So now attacks are labelled 1 to 7. Now we see if attacks of the same type get clustered together. 

```{r}
# Cluster
attacks <- train2.small[train2.small$ATT_FLAG == "True",]
clusterAttacks <- kmeans(attacks[,2:28], centers=5, nstart=20)
attacks$cluster <- clusterAttacks$cluster

# Plot as timeseries
attacks.ts <- ts(attacks)
plot.ts(attacks.ts[,"attack"], col="red")
par(new = TRUE)
plot.ts(train2.small.ts[,"cluster"], axes=FALSE, bty = "n", xlab = "", ylab = "", col="blue")
```
Didn't work out again. My explanation is, because noise is so much, points in the same "attack" or "non attack" regions end up being separated. Plus, the obs with attacks differ from obs without attacks in patterns that are most obvious in a time series plot. However, the clustering techniques we have used here only look at absolute values of the features of each observation, and are not able to pick up on patterns over time. I can think of two things to try here, 1. remove noise and 2. model this problem as a time series somehow. 

Ok so I just remembered that to do clustering properly, I need to first normalize the data. And if I want to add categorical data in, I can replace True with 1 and False with 0. Let's do that. 
```{r}
train2.norm <- train2.small
cats <- c("STATUS_PU1", "STATUS_PU2", "STATUS_PU4", "STATUS_PU6", "STATUS_PU7", "STATUS_PU10", "STATUS_PU11", "STATUS_V2")

# Change categorical data to numeric
for (cat in cats) {
  train2.norm[, cat] <- as.numeric(as.logical(train2.norm[, cat]))
}

# normalize everything
for (name in names(train2.norm)) {
  if (name != "DATETIME" & name != "ATT_FLAG" & name != "cluster" & name != "attack") {
    train2.norm[, name] <- scale(train2.norm[, name]) 
  }
}

```

Clustering
```{r}
km <- kmeans(train2.norm[, 2:36], centers=5, nstart=20)
train2.norm$cluster <- km$cluster

# Plot as timeseries
train2.norm.ts <- ts(train2.norm)
plot.ts(train2.norm.ts[,"attack"], col="red")
par(new = TRUE)
plot.ts(train2.norm.ts[,"cluster"], axes=FALSE, bty = "n", xlab = "", ylab = "", col="blue")
```
Looks a bit better but still not very good :( Sad. 

## Removing Noise
The plots were very noisy, making patterns harder to spot. We could try smoothing methods to de-noise the data
```{r}
# library(smooth)
# library(Mcomp)
# 
# # Example of a noisy plot
# plot.ts(train2.small.ts[,"LEVEL_T7"], ylab="LEVEL_T7")
# 
# sma1 <- sma(train2.small.ts[,"LEVEL_T7"], h=18, silent = FALSE)
# plot(sma1)
```

```{r}
# plot(forecast(sma1))
```

sma clearly didn't work. I got to find something else. 

Code moving average myself
```{r}
library(zoo)

conti_feats <- c("LEVEL_T1", "LEVEL_T2", "LEVEL_T3", "LEVEL_T4", "LEVEL_T5", "LEVEL_T6", "LEVEL_T7", "PRESSURE_J280", "PRESSURE_J269", "PRESSURE_J300", "PRESSURE_J256", "PRESSURE_J289", "PRESSURE_J415", "PRESSURE_J302", "PRESSURE_J306", "PRESSURE_J307", "PRESSURE_J317", "PRESSURE_J14", "PRESSURE_J422", "FLOW_PU1", "FLOW_PU2", "FLOW_PU3", "FLOW_PU4", "FLOW_PU5", "FLOW_PU6", "FLOW_PU7", "FLOW_PU8", "FLOW_PU9", "FLOW_PU10", "FLOW_PU11", "FLOW_V2")

for (feat in conti_feats) {
  new_col <- paste(feat, "_MA10", sep="")
  temp <- rollapply(train2[, feat], width=10, by=1, FUN=mean)
  train2[, new_col] <- c(temp, rep(0, times=9))
}

for (feat in conti_feats) {
  new_col <- paste(feat, "_MA15", sep="")
  temp <- rollapply(train2[, feat], width=15, by=1, FUN=mean)
  train2[, new_col] <- c(temp, rep(0, times=14))
}

for (feat in conti_feats) {
  new_col <- paste(feat, "_MA30", sep="")
  temp <- rollapply(train2[, feat], width=30, by=1, FUN=mean)
  train2[, new_col] <- c(temp, rep(0, times=29))
}
```

```{r}
train2.ts <- ts(train2)
# for (col in colnames(train2.ts)) {
#   if (col != "DATETIME" & col != "ATT_FLAG") {
#     plot.ts(train2.ts[,col], ylab=col, col=c("black"))
#     par(new = TRUE)
#     plot.ts(train2.ts[,"ATT_FLAG"], axes=FALSE, bty = "n", xlab = "", ylab = "", col="red")
#   }
# }
```



High Pass Filter 
```{r}
library(signal)

train2.norm.ts <- ts(train2.norm)
# plot.ts(train2.norm.ts[,"attack"], col="red")
# par(new = TRUE)

butt <- butter(4,0.3,type='high')
highfilter <- filter(butt,train2.small.ts[,"LEVEL_T7"])
plot.ts(highfilter,col='blue')
```
Same as above.....(even with low pass) 
```{r}
library(signal)

train2.norm.ts <- ts(train2.norm)
plot.ts(train2.norm.ts[,"attack"], col="red")
par(new = TRUE)

butt <- butter(2,0.7,type='low')
lowfilter <- filter(butt,train2.small.ts[,"LEVEL_T7"])
plot.ts(lowfilter,col='blue')
```

Cheyb filter
```{r}
train2.norm.ts <- ts(train2.norm)
plot.ts(train2.norm.ts[,"attack"], col="red")
par(new = TRUE)


# length of signal
n <- 10000

# the frequency to be kept
F <- 500
F0 <- 2 * F / n

dataVar <- train2.norm.ts[,"LEVEL_T7"]
filter <- cheby1(6,2,c(F0-F0*.1,F0+F0*.1),type='pass')

signal <- signal::filter(filter,x=dataVar)
# stlVar <- stl(train2.small.ts[,"LEVEL_T7"],s.window="periodic")
plot.ts(signal,col='blue')
```


Low Pass filter worksssss 
```{r}
test.ts = ts(test)
# plot.ts(train2.norm.ts[,"LEVEL_T7"], col='green')

# train2.norm.ts <- ts(train2.norm)
# plot.ts(train2.norm.ts[,"attack"], col="red")
# par(new = TRUE)

plot.ts(test.ts[,"PRESSURE_J300"])

butt <- butter(3,0.01,type='low')
lowfilter <- filter(butt,test.ts[,"PRESSURE_J300"],plane = 'z')
plot.ts(lowfilter,col='blue')

# karmanFilter <- SSModel(lowfilter ~ SSMtrend(1, Q = 100), H = 100)
# out<- KFS(karmanFilter)
# # f <- fft(train2.small.ts[,"LEVEL_T3"])
# 
# ts.plot( out$alphahat, col='blue')
# # ts.plot( out$a, col='red')
# ts.plot( out$att,col='green')
```